---
title: "Smote implementation in unbalanced data"
author: "J. Bravo"
date: "2023-12-20"
output: html_document
---
Load the necessary libraries.
```{r}
library(dplyr) # for functions
library(data.table)
library(janitor)
```
Load more necessary libraries
```{r}
library(randomForest)
library(tidyverse)
set.seed(120)  # Setting seed
library(tidymodels)
tidymodels_prefer()
library(themis)
library(doParallel) # All operating systems
```
Load the dataset.
```{r}
raw_data <- fread("C:/Users/joepb/Desktop/unzipfolder/WA_Crash_Summary.csv")
#raw_data <- fread("/Volumes/my_passport/data_sets/WA_Crash_Summary.csv")
```
Get unique values from data frame.
```{r}
unique(raw_data$"Lighting Condition")
```
```{r}
unique(raw_data$"Weather Condition")
```

Get count of empty string records in the Lighting Condition and Weather Condition fields.
```{r}
raw_data %>%
  filter(raw_data$"Lighting Condition" == "") %>%
  count()
```
```{r}
raw_data %>%
  filter(raw_data$"Weather Condition" == "") %>%
  count()
```

Now that I've seen how to remove the empty strings in each column, I will implement in one chunk.
```{r}
initial_df <- raw_data %>%
  filter(
    raw_data$"Weather Condition" != "",
    raw_data$"Lighting Condition" != ""
    ) %>%
  select(
    "City",
    "Weather Condition",
    "Lighting Condition",
    "Injury Severity"
    )
# Change the column names
colnames(initial_df) <- c(
    "city",
    "weather_condition",
    "lighting_condition",
    "injury_severity"
    )
nrow(initial_df)
```

Store the number of records in its own variables.
```{r}
num_records <- nrow(initial_df)
num_records
```
Get proportions of the other classes
```{r}
prop1 <- nrow(
  initial_df %>%
  filter(
    initial_df$injury_severity == "No Injury Collision")
    ) / num_records
prop2 <- nrow(
  initial_df %>%
  filter(
    initial_df$injury_severity == "Minor Injury Collision")
    ) / num_records
prop3 <- nrow(
  initial_df %>%
  filter(
    initial_df$injury_severity == "Unknown Injury Collision")
    ) / num_records
prop4 <- nrow(
    initial_df %>%
    filter(
        initial_df$injury_severity == "Serious Injury Collision")
    ) / num_records
prop5 <- nrow(
    initial_df %>%
    filter(
        initial_df$injury_severity == "Fatal Collision")
    ) / num_records
print(paste("Proportion for No Injury Collision", prop1))
print(paste("Proportion for Minor Injury Collision", prop2))
print(paste("Proportion for Unknown Injury Collision", prop3))
print(paste("Proportion for Serious Injury Collision", prop4))
print(paste("Proportion for Fatal Collision", prop5))
```
The print statements above detail the distribution of the proportions for each class in the Injury Severity column. There is a clear imbalance that will be corrected via SMOTE.

Tidyverse doesConvert to factor
```{r}
initial_df$injury_severity <- as.factor(initial_df$injury_severity)
```

Will name this data frame balanced_df.
```{r}
# A more balanced dataset
balanced_df <- SMOTE(
  initial_df,
  initial_df$injury_severity
  )
# View distribution of response variable in new dataset
table(balanced_df$injury_severity)
```

The initial dataframe has some simple preprocessing needed to fit a model.
Next, will perform any remaining preprocessing using recipes.
Quick view of the initial data frame.
```{r}
tail(initial_df)
```
A "tail" check reveals that the configuration of the data frame does include the wanted
columns.

Step 1 was transformation of the raw data frame to the initial data frame.
```{r}
df <- raw_data %>%
  filter(
    raw_data$"Weather Condition" != "",
    raw_data$"Lighting Condition" != ""
  ) %>%
  select(
    #"City",
    "Weather Condition",
    "Lighting Condition",
    "Injury Severity"
  ) %>%
  # Converting all the character data types to factors
  mutate_if(is.character, as.factor) %>%
  # Change the column names to snake and lower case
  clean_names()
```
So in the above command I incorporated the conversion of character data types to factors
for all the string types.

Simple training/test set split.
```{r}
crash_split <- initial_split(df, prop = 0.75)
train_data <- training(crash_split)
test_data <- testing(crash_split)
```
Get the dimensions of the dataframes.
```{r}
train_data %>% dim()
test_data %>% dim()
```
Want to apply 10-fold cross-validation.
```{r}
train_cv <- vfold_cv(train_data, v = 10)
```
Probably won't use the 10-fold cross-validation.
Now, want to create a recipe for the random forest model.
```{r}
rf_recipe <-
  recipe(injury_severity  ~ ., data = train_data) %>%
  #step_downsample(injury_severity, under_ratio =0.75)
  #step_smote(injury_severity)
  step_upsample(injury_severity, over_ratio = 0.50)
  #prep() %>%
  #juice()
rf_recipe
```
Train the recipe
```{r}
trained_recipe <- rf_recipe %>% prep(train_data)
trained_recipe
```
Create random forest model specifications.
```{r}
rf_model <-
    rand_forest(trees = 1000) %>%
    set_engine("randomForest") %>%
    set_mode("classification")
rf_model
```
Setup the workflow
```{r}
rf_wflow <-
  workflow() %>%
  add_model(rf_model) %>%
  add_recipe(rf_recipe)
rf_wflow
```

```{r}
training <- rf_recipe %>%
  bake(new_data = NULL) %>%
  count(injury_severity, name = "training")
training
```

Now, fit the workflow.
```{r}
rf_fit <- fit(rf_wflow, data = train_data)
rf_fit
```

When I need a quick look at the training data.
```{r}
summary(train_data)
```

want to resample and gather the performance metrics
```{r}
#perf_metrics <- metric_set(roc_auc, accuracy, sensitivity, specificity)
perf_metrics <- metric_set(roc_auc, accuracy)
# random forest resample
rf_rs <- rf_wflow %>%
  fit_resamples(
    resamples = train_cv,
    metrics = perf_metrics,
    control = control_resamples(save_pred = TRUE)
  )
rf_rs
```
Evaluate the model
```{r}
collect_metrics(rf_rs)
```
```{r}
rf_rs %>%
  conf_mat_resampled()
```

### Prototype the Random Forest model - Take 1
Will not use workflow for this procedure, but will invoke recipes.
Step 1a: Initiate the recipe
```{r}
rf_recipe <-
  recipe(injury_severity  ~ ., data = train_data) %>%
  step_upsample(injury_severity, over_ratio = 0.50)
rf_recipe
```
Step 1b: Train the data
```{r}
# Using prep on the training data
trained_rf_recipe <- rf_recipe %>% prep(train_data)
trained_rf_recipe
```
Step 1c: Bake the recipe
```{r}
train_baked <- trained_rf_recipe %>% bake(train_data)
test_baked <- trained_rf_recipe %>% bake(test_data)
```
Step 1d: Crete the Random Forest model
```{r}
rf_model <- rand_forest(mode = "classification", engine = "randomForest")

rf_model_fit <- rf_model %>%
  fit(injury_severity  ~ ., data = train_baked)

rf_model_fit %>% extract_fit_engine() %>% varImpPlot(sort = TRUE)

rf_model_pred <- test_baked %>%
  bind_cols(predict(rf_model_fit, new_data = test_baked)) %>%
  select(injury_severity, .pred_class, everything())
rf_model_pred

rf_model_pred %>% metrics(injury_severity, .pred_class)
```
### Prototype the Random Forest model - Take 2
Will use workflow for this procedure.
Step 2a: Initiate the recipe
The predictors and outcomes with the preprocesing steps.
```{r}
rf_recipe <-
  recipe(injury_severity  ~ ., data = train_data) %>%
  step_upsample(injury_severity, over_ratio = 0.50)
rf_recipe
```
Step 2b: Train the data
Create a parsnip model, and then build a workflow with the model and recipe
```{r}
# Using prep on the training data
rf_model_wflow <-
  workflow() %>%
  add_model(rf_model) %>%
  add_recipe(rf_recipe)

rf_model_wflow
```
Step 2c: Fit workflow and data to model
Call to 'fit()' is used to estimate the preprocessing steps and then fit the random forest model.
```{r}
rf_model_fit <- fit(rf_model_wflow, data = train_data)
rf_model_fit
```
Step 2d: Use the 'predict()' function to use validation (test) data
```{r}
library(caret)
pred1 <- predict(rf_model_fit, new_data = test_data)
pred1
```
Step 2e: Extract the performance metrics
```{r}
rf_model_pred_2 <- test_data %>%
  bind_cols(pred1) %>%
  select(injury_severity, .pred_class, everything())
rf_model_pred_2

rf_model_pred_2 %>% metrics(injury_severity, .pred_class)
```
### Prototype the Random Forest model - Take 3
In this iteration of the RF model, I will use the a progression that includes a validation set to obtain
resampled summary statistics to determine best classification model for this dataset.
Note, will use the same training data established earlier.
This step should require about 6 steps.
Step 3a: Recipe
```{r}
rf_recipe_3 <-
  recipe(injury_severity  ~ ., data = train_data) %>%
  step_upsample(injury_severity, over_ratio = 0.50)
rf_recipe_3
```
Step 3b: Model
```{r}
rf_model_3 <-
    rand_forest(trees = 1000) %>%
    set_engine("randomForest") %>%
    set_mode("classification")
rf_model_3
```
Step 3c: Workflow
```{r}
rf_model_wflow_3 <-
  workflow() %>%
  add_model(rf_model_3) %>%
  add_recipe(rf_recipe_3)
rf_model_wflow_3
```
Step 3d: Folds
```{r}
val_set <- validation_split(train_data, prop = 3/4)
#val_set <- initial_validation_split(train_data, prop = 3/4)
val_set
```


Step 3e: Resampling
```{r}
# Performance metrics
perf_metrics_3 <- metric_set(roc_auc, accuracy, sensitivity, specificity)
# random forest resample
rf_rs_3 <- rf_model_wflow_3 %>%
  fit_resamples(
    resamples = val_set,
    metrics = perf_metrics_3,
    control = control_resamples(save_pred = TRUE)
  )
rf_rs_3
```
Step 3f: Performance Metrics
```{r}
collect_metrics(rf_rs_3)
```
```{r}
# Confusion Matrix
rf_rs_3 %>%
  conf_mat_resampled()
```
There are many instances where the model incorrectly predicted the outcome from the dataset. The accuracy from the resampling confirms this as well.
### Check processing power
Number of physical cores in the hardware
```{r}
parallel::detectCores(logical = FALSE)
```
The number of possible independent processes that can be simultaneously used
```{r}
parallel::detectCores(logical = TRUE)
```
### Prototype the kNN model - Take 4
Step 4a: Initiate the recipe
```{r}
# First variation of the recipe
#crash_data_recipe <-
#  recipe(injury_severity  ~ ., data = train_data) %>%
#  #step_upsample(injury_severity, over_ratio = 0.75) %>%
#  step_dummy(lighting_condition, weather_condition) %>%
#  step_smote(injury_severity)
#crash_data_recipe

# Second variation of the recipe
crash_data_recipe <-
  recipe(injury_severity  ~ ., data = train_data) %>%
  step_dummy(lighting_condition, weather_condition) %>%
  step_smote(injury_severity, over_ratio = 0.75)
crash_data_recipe
```
Step 4b: Train the data
```{r}
# Using prep on the training data
trained_knn_recipe <- knn_recipe %>% prep(train_data)
trained_knn_recipe
```
Step 4c: Bake the recipe
```{r}
train_baked <- trained_knn_recipe %>% bake(train_data)
test_baked <- trained_knn_recipe %>% bake(test_data)
```
Step 4d: Crete the Random Forest model
```{r}
#library(kknn)
#knn_model <- nearest_neighbor() %>%
#  set_engine("kknn") %>%
#  set_mode("classification")
knn_model <- nearest_neighbor(mode = "classification", engine = "kknn")

knn_model_fit <- knn_model %>%
  fit(injury_severity  ~ ., data = train_baked)

knn_model_fit %>% extract_fit_engine() %>% varImpPlot(sort = TRUE)

knn_model_pred <- test_baked %>%
  bind_cols(predict(knn_model_fit, new_data = test_baked)) %>%
  select(injury_severity, .pred_class, everything())
knn_model_pred

knn_model_pred %>% metrics(injury_severity, .pred_class)
```
Step 4b: Set up the kNN model specifications
```{r}
knn_model <- nearest_neighbor(
  mode = "classification",
  engine = "kknn",
  neighbors = 10,
)
knn_model
```
Step 4c: Create workflow
```{r}
knn_model_wflow <-
  workflow() %>%
  add_model(knn_model) %>%
  add_recipe(crash_data_recipe)
knn_model_wflow
```
Step 4d: Performance metrics
```{r}
cluster <- makePSOCKcluster(4)
registerDoParallel(cluster)
# Performance metrics
perf_metrics <- metric_set(roc_auc, accuracy, sensitivity, specificity)
# Begin timing for this model
start_time <- Sys.time()
# kNN resample
knn_rs <- knn_model_wflow %>%
  fit_resamples(
    resamples = val_set,
    metrics = perf_metrics,
    control = control_resamples(save_pred = TRUE)
  )
# End time and get the difference 
end_time <- Sys.time()
end_time - start_time
knn_rs
stopCluster(cluster)
```
### Prototype the Naive Bayes model - Take 5
Step 5a: Initiate the recipe
```{r}
# Recipe
crash_data_rec <-
  recipe(injury_severity  ~ ., data = train_data) %>%
  step_downsample(injury_severity, under_ratio = 4)
crash_data_rec
```
Step 5b: Set up the Naive Bayes model specifications
```{r}
# Need new package for h2o engine
library(discrim)
library(agua)
#library(naivebayes)
naive_bayes_model <- naive_Bayes(
  mode = "classification",
  Laplace = 2.0,
  engine = "naivebayes"
  #engine = "h2o"
)
naive_bayes_model
```
Step 5c: Create workflow
```{r}
nb_model_wflow <-
  workflow() %>%
  add_model(naive_bayes_model) %>%
  add_recipe(crash_data_rec)
nb_model_wflow
```
Step 5d: Re-sampling
```{r}
severity_folds <- vfold_cv(train_data, strata = injury_severity)
cluster <- makePSOCKcluster(4)
registerDoParallel(cluster)
# Performance metrics
perf_metrics <- metric_set(roc_auc, accuracy, sensitivity, specificity)
# Begin timing for this model
start_time <- Sys.time()
# naive bayes resample
nb_rs <- nb_model_wflow %>%
  fit_resamples(
    #resamples = val_set,
    resamples = severity_folds,
    #resamples = train_cv,
    metrics = perf_metrics,
    control = control_resamples(save_pred = TRUE)
  )
# End time and get the difference 
end_time <- Sys.time()
end_time - start_time
nb_rs
stopCluster(cluster)
```
Step 5e: Performance Metrics
```{r}
collect_metrics(nb_rs)
```
The confusion matrix
```{r}
# Confusion Matrix
nb_rs %>%
  conf_mat_resampled()
```
### Prototype the Support Vector Machine (SVM) model - Take 6
Step 6a: Initiate the recipe
```{r}
# Recipe
svm_recipe <-
  recipe(injury_severity  ~ ., data = train_data) %>%
  step_dummy(lighting_condition, weather_condition) %>%
  step_downsample(injury_severity, under_ratio = 4)
svm_recipe
```
Step 6b: Set up the SVM model specifications
```{r}
library(kernlab)
svm_model <- svm_rbf(
  cost = tune(),
  rbf_sigma = tune()
  ) %>%
  set_mode("classification") %>%
  set_engine("kernlab")
svm_model
```
Step 6c: Create workflow
```{r}
svm_model_wflow <-
  workflow() %>%
  add_model(svm_model) %>%
  add_recipe(svm_recipe)
svm_model_wflow
```
Step 6d: Re-sampling
```{r}
severity_folds <- vfold_cv(train_data, strata = injury_severity)
cluster <- makePSOCKcluster(4)
registerDoParallel(cluster)
# Performance metrics
perf_metrics <- metric_set(roc_auc, accuracy, sensitivity, specificity)
# Begin timing for this model
start_time <- Sys.time()
# svm resample
#svm_rs <- svm_model_wflow %>%
#  fit_resamples(
#    #resamples = val_set,
#    resamples = severity_folds,
#    #resamples = train_cv,
#    metrics = perf_metrics,
#    control = control_resamples(save_pred = TRUE)
#  )

ctrl <- control_grid(verbose = FALSE, save_pred = TRUE)

formula_res <-
  svm_model %>% 
  tune_grid(
    injury_severity ~ .,
    resamples = train_cv,
    metrics = perf_metrics,
    control = ctrl
  )
formula_res

# End time and get the difference 
end_time <- Sys.time()
end_time - start_time
formula_res
stopCluster(cluster)
```
Step 6e: Performance Metrics
```{r}
collect_metrics(formula_res)
```
The confusion matrix
```{r}
# Confusion Matrix
formula_res %>%
  conf_mat_resampled()
```
### Prototype the Support Vector Machine (SVM) model - Take 7
This iteration will attempt a different progression in creating the desired SVM model.
First, want to get a subset that is 5% of the df data frame.
```{r}
num_records <- nrow(df)
sample_size <- ceiling(num_records * 0.025)
subset_df <- df[sample(1:num_records, sample_size, replace = FALSE),]
head(subset_df)
```
Step 7a: Create splits, folds, performance metrics, and control object
```{r}
# Splits
splits <- initial_split(subset_df, prop = 0.50, strata = injury_severity)
train_split <- training(splits)
test_split <- testing(splits)
# Folds
severity_folds <- vfold_cv(train_split, v = 10, strata = injury_severity)
set.seed(420)
# Performance metrics
perf_metrics <- metric_set(roc_auc, accuracy, sensitivity, specificity)
# Control Object
ctrl_obj <- control_grid(verbose = FALSE, save_pred = TRUE)
```
Step 7b: Initiate the recipe
Will fit a radial basis function (rbf) SVM to crashes and tune SVM cost parameter and sigma parameter in the kernel function.
```{r}
# Recipe
svm_rec <-
  recipe(injury_severity  ~ ., data = train_split) %>%
  step_upsample(injury_severity, over_ratio = 0.75) %>%
  step_dummy(lighting_condition, weather_condition)
  #step_downsample(injury_severity, under_ratio = 4)
svm_rec
```
Step 7c: Set up the SVM model specifications
```{r}
library(kernlab)
library(mlbench)
svm_model <- svm_rbf(
  cost = tune(),
  rbf_sigma = tune()
  ) %>%
  set_mode("classification") %>%
  set_engine("kernlab")
svm_model
```
Step 7d: Create workflow
Set up the workflow and then feed it to the svm model.
```{r}
svm_wflow <-
  workflow() %>%
  add_model(svm_model) %>%
  add_recipe(svm_rec)
svm_wflow
```
Step 7e: Executing tune grid
```{r}
cluster <- makePSOCKcluster(4)
registerDoParallel(cluster)
# Begin timing for this model
start_time <- Sys.time()

svm_initial <-
  svm_wflow %>%
  tune_grid(
    resamples = severity_folds,
    metrics = perf_metrics,
    control = ctrl_obj
  )
end_time <- Sys.time()
end_time - start_time
svm_initial
stopCluster(cluster)
```
```{r}
collect_metrics(svm_initial)
```
Step 7e: Create parameters, update, and tune grid
```{r}
cluster <- makePSOCKcluster(4)
registerDoParallel(cluster)
# Parameters
svm_params <-
  svm_wflow %>%
  parameters() %>%
  update(rbf_sigma = rbf_sigma(c(-8, -2)))
# Grid
start_grid <-
  svm_params %>%
  update(
    cost = cost(c(-9, 4)),
    rbf_sigma = rbf_sigma(c(-6, -4))) %>%
  grid_regular(levels = 2)
set.seed(2)
# Tune Grid
svm_initial <-
  svm_wflow %>%
  tune_grid(resamples = severity_folds, grid = start_grid, metrics = perf_metrics)
stopCluster(cluster)
```
### Prototype the Random Forest model - Take 8
This iteration will attempt a different progression in creating the desired Random Forest (RF) model.
First, want to get a subset that is 5% of the df data frame.
```{r}
num_records <- nrow(df)
sample_size <- ceiling(num_records * 0.025)
subset_df <- df[sample(1:num_records, sample_size, replace = FALSE),]
head(subset_df)
```
Step 8a: Create splits, folds, performance metrics, and control object
```{r}
# Splits
splits <- initial_split(subset_df, prop = 0.50, strata = injury_severity)
train_split <- training(splits)
test_split <- testing(splits)
# Folds
severity_folds <- vfold_cv(train_split, v = 10, strata = injury_severity)
set.seed(420)
# Performance metrics
perf_metrics <- metric_set(roc_auc, accuracy, sensitivity, specificity)
# Control Object
ctrl_obj <- control_grid(verbose = FALSE, save_pred = TRUE)
```
Step 8b: Recipe
```{r}
rf_rec <-
  recipe(injury_severity  ~ ., data = train_split) %>%
  step_upsample(injury_severity, over_ratio = 0.50)
rf_rec
```
Step 8c: Model Specifications
```{r}
rf_model <-
  rand_forest(
      mtry = tune(),
      trees = tune(),
      min_n = tune()
      ) %>%
  set_mode("classification") %>%
  set_engine("randomForest")
rf_model
```
Step 8d: Workflow
```{r}
rf_wflow <-
  workflow() %>%
  add_model(rf_model) %>%
  add_recipe(rf_rec)
rf_wflow
```
Step 8e: Executing Tune Grid
```{r}
cluster <- makePSOCKcluster(4)
registerDoParallel(cluster)
# Begin timing for this model
start_time <- Sys.time()

rf_initial <-
  rf_wflow %>%
  tune_grid(
    resamples = severity_folds,
    metrics = perf_metrics,
    control = ctrl_obj
  )
end_time <- Sys.time()
end_time - start_time
rf_initial
stopCluster(cluster)
```
Step 8f: Collect performance metrics
```{r}
collect_metrics(rf_initial)
```
### Prototype the Random Forest model - Take 9
This iteration will attempt a different progression in creating the desired k - Nearest Neighbor (kNN) model.First, want to get a subset that is 5% of the df data frame.
Step 9a: Recipe
```{r}
knn_recipe <-
  recipe(injury_severity  ~ ., data = train_split) %>%
  step_dummy(lighting_condition, weather_condition) %>%
  step_smote(injury_severity, over_ratio = 0.75)
knn_recipe
```
Step 9b: Model Specifications
```{r}
library(kknn)
knn_model <- nearest_neighbor(
  neighbors = tune(),
  weight_func = tune(),
  dist_power = tune(),
  mode = "classification",
  engine = "kknn"
  )
knn_model
```
Step 4c: Workflow
```{r}
knn_wflow <-
  workflow() %>%
  add_model(knn_model) %>%
  add_recipe(knn_recipe)
knn_wflow
```
Step 4d: Create Tuning Grid
```{r}
cluster <- makePSOCKcluster(4)
registerDoParallel(cluster)
# Begin timing for this model
start_time <- Sys.time()

knn_initial <-
  knn_wflow %>%
  tune_grid(
    resamples = severity_folds,
    metrics = perf_metrics,
    control = ctrl_obj
  )
end_time <- Sys.time()
end_time - start_time
knn_initial
stopCluster(cluster)
```
Step 8f: Collect performance metrics
```{r}
collect_metrics(rf_initial)
```
